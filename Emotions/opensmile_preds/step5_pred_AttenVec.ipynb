{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391d368-3afa-44f3-9084-cc920175c28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4611a40d-24c6-4720-9d8b-d6fdd0c5341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab77fa0-6b96-41d5-a8cb-e6cf4f26cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_location = '/home/a/Desktop/MSP-Podcast/pipeline/INPUTS_OUTPUTS/Outputs/'\n",
    "\n",
    "\n",
    "with open(os.path.join(os.path.join(root_location, \"Short_files.json\")), \"r\") as openfile:\n",
    "    audio_files = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb4ea72-f4ac-46a0-9716-5d93ad42e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, f_info  in audio_files.items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8196a53e-6b1d-4cdf-b2fa-0092bd3b4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = f_info['filepaths']['opensmile_lld']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4972514-7be2-4e25-a294-2ad7ef963e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TryToFloat(single_data):\n",
    "    try:\n",
    "        return float(single_data)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def LoadFeature(filename):\n",
    "    content = open(filename, 'r').read()\n",
    "    data = content.split('@data\\n')[1].split('\\n')\n",
    "    data = filter(None, data)\n",
    "    feature = [[TryToFloat(data_split) for data_split in d.split(',') \\\n",
    "                if TryToFloat(data_split)!=None] for d in data]\n",
    "    return np.array(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f7c15-80f6-4949-b8e4-27f775a6b50c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de5c2073-7f2f-4d72-a19e-179f7fcecff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.000000e+00,  2.098476e+02,  7.457917e-01, ..., -5.050770e-01,\n",
       "        -2.337668e+00, -1.067880e-01],\n",
       "       [ 1.600000e-02,  2.485446e+02,  7.827879e-01, ..., -9.466939e-01,\n",
       "        -3.285222e+00, -7.556780e-02],\n",
       "       [ 3.200000e-02,  2.854767e+02,  8.175290e-01, ..., -2.302814e+00,\n",
       "        -3.532829e+00, -7.100361e-01],\n",
       "       ...,\n",
       "       [ 6.608000e+00,  0.000000e+00,  0.000000e+00, ..., -5.839880e+00,\n",
       "        -3.835547e+00,  1.459241e+00],\n",
       "       [ 6.624000e+00,  0.000000e+00,  0.000000e+00, ..., -4.503720e+00,\n",
       "        -2.473446e+00,  1.987281e+00],\n",
       "       [ 6.624000e+00,  0.000000e+00,  0.000000e+00, ..., -2.556796e+00,\n",
       "        -1.113743e+00,  1.123780e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoadFeature(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649ef2e-7431-4422-90c6-a71f26c0bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b3df011-bb29-442a-a0ce-89d8116eb6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import SimpleRNN, LSTM, Lambda, Input, Dot, Concatenate\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from keras import backend as K\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "import argparse\n",
    "# Ignore warnings & Fix random seed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(999)\n",
    "random_seed=99\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc4426e-9d32-44c9-85ad-308dcf530f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean():  \n",
    "    def func(x):\n",
    "        return K.mean(x, axis=1, keepdims=False)\n",
    "    return Lambda(func)\n",
    "\n",
    "def reshape_1():\n",
    "    def func(x):\n",
    "        feat_num = 130\n",
    "        chunk_num = 11\n",
    "        return K.reshape(x, (1, chunk_num, feat_num))\n",
    "    return Lambda(func)\n",
    "\n",
    "def reshape_2():\n",
    "    def func(x):\n",
    "        feat_num = 130\n",
    "        chunk_num = 17\n",
    "        return K.reshape(x, (1, chunk_num, feat_num))\n",
    "    return Lambda(func)\n",
    "\n",
    "# Split Original batch Data into Small-Chunk batch Data Structure with different step window size\n",
    "def DiffRslChunkSplitTestingData(Batch_data, chunk_num):\n",
    "    \"\"\"\n",
    "    Note!!! This function can't process sequence length which less than given chunk_size (i.e.,1sec=62frames)\n",
    "    Please make sure all your input data's length are greater then given chunk_size\n",
    "    \"\"\"\n",
    "    chunk_size = 62  # (62-frames*0.016sec) = 0.992sec\n",
    "    n = 1\n",
    "    num_shifts = n*chunk_num-1  # max_length = 11sec, chunk needs to shift 10 times to obtain total 11 chunks for each utterance\n",
    "    Split_Data = []\n",
    "    for i in range(len(Batch_data)):\n",
    "        data = Batch_data[i]\n",
    "        # Shifting-Window size varied by differenct length of input utterance => Different Resolution\n",
    "        step_size = int(int(len(data)-chunk_size)/num_shifts)      \n",
    "        # Calculate index of chunks\n",
    "        start_idx = [0]\n",
    "        end_idx = [chunk_size]\n",
    "        for iii in range(num_shifts):\n",
    "            start_idx.extend([start_idx[0] + (iii+1)*step_size])\n",
    "            end_idx.extend([end_idx[0] + (iii+1)*step_size])    \n",
    "        # Output Split Data\n",
    "        for iii in range(len(start_idx)):\n",
    "            Split_Data.append( data[start_idx[iii]: end_idx[iii]] )    \n",
    "    return np.array(Split_Data)\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae193978-1f64-4eed-9790-8223cf29e21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32dbd06b-bcd8-47aa-80fb-918929b2443d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('/home/a/Desktop/MSP-Podcast/pipeline/INPUTS_OUTPUTS/Outputs/Short_split_OpenSmile_lld_IS13ComParE/MSP-PODCAST_5198_0001.arff',\n",
       "      dtype='<U124')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56262cf5-19aa-467e-9f1e-bf1b33853169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/499 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music/speech inference: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Music/speech inference: \")\n",
    "for filename, f_info in tqdm(audio_files.items()):\n",
    "    f_path = f_info['filepaths']['opensmile_lld']\n",
    "    audio = LoadFeature(f_path)#[:,1:].astype(np.float32)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea40bab0-9e82-4df1-8d09-06794f4dbbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 131)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5215c-2ae3-436c-99f1-6fb08f767941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winston_base",
   "language": "python",
   "name": "winston_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
