{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472f0aec-77e1-4d75-bf93-87aea93533ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep  3 15:31:18 2018\n",
    "\n",
    "@author: winstonlin\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import subprocess\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102753ab-44ad-4029-8481-e8463746b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/a/Desktop/MSP-Podcast/pipeline/'\n",
    "\n",
    "output_location = 'INPUTS_OUTPUTS/Outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1d4b13-fb52-482f-9355-85b5c4fd133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENSMILE_PATH = '/home/a/Desktop/MSP-Podcast/pipeline/emotion_retrieval_final/opensmile/opensmile/build/progsrc/smilextract/SMILExtract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b02e1f6-d062-4131-aab2-8e25773c82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SmileExtract(input_path, out_path, audio_files, feature_type, desc_type = 'lld'):\n",
    "    ERROR_record = ''\n",
    "    for filename, f_info in tqdm(audio_files.items()):\n",
    "        f_path = f_info['filepaths']['wav']\n",
    "        if '.wav' in f_path:\n",
    "            input_file = f_path\n",
    "            output_file = os.path.join(out_path, filename + '.arff')\n",
    "            f_info['filepaths']['opensmile_'+desc_type] = output_file\n",
    "\n",
    "            if desc_type == 'lld':\n",
    "\n",
    "                cmd = OPENSMILE_PATH+' -l 1 -C opensmile-2.3.0_lld/IS13_ComParE.conf -I ' + input_file + ' -O ' + output_file\n",
    "            elif desc_type == 'hld':\n",
    "                cmd = OPENSMILE_PATH+' -l 1 -C opensmile-2.3.0_hld/IS13_ComParE.conf -I ' + input_file + ' -O ' + output_file\n",
    "            else:\n",
    "                raise ValueError('Unsupport desc_type Type!')\n",
    "            try:\n",
    "                subprocess.call(cmd, shell=True)\n",
    "            except:\n",
    "                ERROR_record += 'Error: '+fileNames[i]+'\\n'\n",
    "\n",
    "        else:\n",
    "            ERROR_record += 'Source not WAV file: ' +fileNames[i]+'\\n'\n",
    "    print(ERROR_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88625c5-752e-4a7a-82b8-db26d38ee1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# feature_arff to feature_mat\n",
    "def TryToFloat(single_data):\n",
    "    try:\n",
    "        return float(single_data)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def LoadFeature(filename):\n",
    "    content = open(filename, 'r').read()\n",
    "    data = content.split('@data\\n')[1].split('\\n')\n",
    "    data = filter(None, data)\n",
    "    feature = [[TryToFloat(data_split) for data_split in d.split(',') \\\n",
    "                if TryToFloat(data_split)!=None] for d in data]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ed2308-0718-45b0-8c16-cab85a20790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.join(root, output_location), \"Short_files.json\"), \"r\") as openfile:\n",
    "    audio_files = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a422ed3d-76e4-4372-8bf7-bac666cc346a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/499 [00:00<00:20, 24.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running openSMILE lld  extractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:18<00:00, 26.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################### eGeMAPS-LLD ####################\n",
    "feat = 'OpenSmile_lld_IS13ComParE'  # Dim=130 LLDs\n",
    "\n",
    "# Part 1: OpenSmile => Arff File\n",
    "input_path = os.path.join(root, output_location, \"Short_split_file\")\n",
    "out_path = os.path.join(root, output_location, \"Short_split_\"+feat)\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "print(\"Running openSMILE lld  extractor\")\n",
    "SmileExtract(input_path, out_path, audio_files, feature_type='IS13ComParE', desc_type='lld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57faad1c-ca75-4297-9ae6-09ff0b2031b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/499 [00:00<00:22, 22.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running openSMILE hld extractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:21<00:00, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feat = 'OpenSmile_hld_IS13ComParE' # Dim=6373 HLDs\n",
    "input_path = os.path.join(root, output_location, \"Short_split_file\")\n",
    "out_path = os.path.join(root, output_location, \"Short_split_\"+feat)\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "print(\"Running openSMILE hld extractor\")\n",
    "SmileExtract(input_path, out_path, audio_files, feature_type='IS13ComParE', desc_type='hld') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03860884-8f8d-44c8-8d6b-40f6b6602987",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(audio_files, indent=4)\n",
    "with open(os.path.join(root, output_location, \"Short_files.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6316881f-81f4-4919-a1ad-bf0070a8002a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-67aa0ebee22b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-67aa0ebee22b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    end of file\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "end of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff3ce8-a5a1-40a9-900f-1c5fc016519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in glob(os.path.join(out_path,'*.arff')):\n",
    "#     basename = os.path.basename(filename).split('.')[0]\n",
    "#     data = LoadFeature(filename)\n",
    "#     # data = np.array(data)\n",
    "#     audio_files[basename]['opensmile_lld'] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890e907-6272-4e50-8e17-878e609dd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7485f-31d1-41d7-bf2e-2dd61e67316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savemat(output_file, {'Audio_data':data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743d0a3-c1f4-482c-87e3-43eb0efe6256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d418d9-3a1f-40e5-b73b-bf59c18c8167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f679547-b74c-4440-8b38-6ed5544c5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob(os.path.join(out_path,'*.arff')):\n",
    "    basename = os.path.basename(filename).split('.')[0]\n",
    "    data = LoadFeature(filename)\n",
    "    # data = np.array(data)\n",
    "    audio_files[basename]['opensmile_hld'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5108c92-ae57-4e8f-b1be-f2aa01d47c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2864ad4-6642-48ba-a704-f28b561651d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(audio_files, indent=4)\n",
    "with open(os.path.join(root, output_location, \"Short_files.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c83fb-f8e1-48b2-b5b7-994901abd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines \n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import textgrid\n",
    "import subprocess\n",
    "import shutil\n",
    "from glob import glob\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def parse_exist_files(root_path):\n",
    "    FileNames = []\n",
    "    for dirPath, dirNames, fileNames in os.walk(root_path):\n",
    "        fileNames = sorted(fileNames)\n",
    "        for i in range(len(fileNames)):\n",
    "            fname = fileNames[i]\n",
    "            fname = fname.replace('.wav','')\n",
    "            fname = fname.replace('.txt','')\n",
    "            fname = fname.replace('.TextGrid','')\n",
    "            FileNames.append(fname)\n",
    "    FileNames = np.unique(np.array(FileNames)).tolist()  \n",
    "    return FileNames\n",
    "##############################################################################\n",
    "def trim_time(time_d):\n",
    "    time_d = str(time_d)\n",
    "    if '.' in time_d:\n",
    "        if len(time_d.split('.')[-1])>2:\n",
    "            trim_digits = len(time_d.split('.')[-1])-2\n",
    "            time_d = time_d[:-trim_digits]\n",
    "    else:\n",
    "        time_d += '.00'\n",
    "    return time_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fed95-4cf1-4969-8a7c-7bb4426e8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Parameters\n",
    "output_root = '../INPUTS_OUTPUTS/Outputs'\n",
    "\n",
    "\n",
    "output_short_file = os.path.abspath(os.path.join(output_root, 'Short_split_file'))\n",
    "\n",
    "\n",
    "reseg_output_file = os.path.join(output_root,'Long_reseg_file')\n",
    "mfa_corpus_root = os.path.join(output_root,'mfa_corpus/speaker1')\n",
    "mfa_aligned_root = os.path.join(output_root,'mfa_align_rsl/speaker1')\n",
    "seg_threshold = 0.3 # in secs\n",
    "\n",
    "\n",
    "with open(os.path.join(output_root, \"Short_files.json\"), \"r\") as openfile:\n",
    "    short_files = json.load(openfile)\n",
    "    \n",
    "with open(os.path.join(output_root, \"Long_files.json\"), \"r\") as openfile:\n",
    "    long_files = json.load(openfile)\n",
    "\n",
    "os.mkdir(reseg_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35796d37-b1fc-4dd0-b931-86982f4facec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info for any non-align files\n",
    "missing_files = list(set(parse_exist_files(mfa_corpus_root))-set(parse_exist_files(mfa_aligned_root)))\n",
    "missing_files = sorted(missing_files)\n",
    "print(\"*****NOTE: Missing Aligned Files= \"+str(len(missing_files))+\" *****\")\n",
    "\n",
    "\n",
    "def save_segment_text(out_name, text):\n",
    "    with open(out_name,'w', encoding='utf8') as wf:\n",
    "        wf.write(text)\n",
    "        wf.close()\n",
    "        \n",
    "        \n",
    "def read_segment_text(file_name):\n",
    "    with open(file_name) as f:\n",
    "        lines = f.read()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c497bab-41f9-4f4e-a51f-5765f01ab9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_time(time_d):\n",
    "    time_d = str(time_d)\n",
    "    if '.' in time_d:\n",
    "        if len(time_d.split('.')[-1])>2:\n",
    "            trim_digits = len(time_d.split('.')[-1])-2\n",
    "            time_d = time_d[:-trim_digits]\n",
    "    else:\n",
    "        time_d += '.00'\n",
    "    return time_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f64de-c383-4395-a4f9-c4b0881f8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestr_to_seconds(time_str):\n",
    "    ftr = [3600,60,1]\n",
    "\n",
    "    seconds = sum([a*b for a,b in zip(ftr, map(int,time_str.split('.')[0].split(':')))])\n",
    "    remainder = float(time_str.split('.')[1])/100\n",
    "    total_time = seconds+ remainder\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed249eb-d935-4bb2-99c0-ae3e4acac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "aligned_files_all = sorted(os.listdir(mfa_aligned_root))\n",
    "for filepath in glob(os.path.join(mfa_aligned_root,'*.TextGrid')):\n",
    "    \n",
    "    filename = os.path.basename(filepath).split('.')[0]\n",
    "    align_rsl = textgrid.TextGrid.fromFile(filepath)[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f224ef-2ba9-4bb2-9da0-5fc3a7880c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = long_files[filename]['start']\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9eb722-2596-4a2d-a911-4eef79d8e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time2 = \"0:00:10.20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dbf87-6a9e-4ca1-a9b5-3076e4256e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timestr_to_seconds(start_time) + timestr_to_seconds(start_time2)\n",
    "trim_time(timedelta(seconds = start_time2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c01f00-4bea-47d1-b2a8-999ba7828075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # obtain split timestamps\n",
    "    seg_times = []\n",
    "    seg_asr = [\"\",]\n",
    "    for j in range(len(align_rsl)):\n",
    "        word = align_rsl[j].mark\n",
    "        word_t_start = align_rsl[j].minTime\n",
    "        word_t_end = align_rsl[j].maxTime\n",
    "        duration = word_t_end - word_t_start\n",
    "        if word==\"\" and duration>=seg_threshold:\n",
    "            seg_times.append(str((word_t_start+word_t_end)/2))\n",
    "            seg_asr.append(\"\")\n",
    "        elif word == \"\":\n",
    "            continue\n",
    "        else:\n",
    "            seg_asr[-1] += word + ' ' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winston_base",
   "language": "python",
   "name": "winston_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
