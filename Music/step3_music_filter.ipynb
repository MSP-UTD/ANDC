{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c71f86-00f7-4a2b-9f05-11e998ff43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from glob import glob\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b1e3e3-5c80-401e-a2c5-4b30dde630c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wada_snr(wav):\n",
    "    # Direct blind estimation of the SNR of a speech signal.\n",
    "    #\n",
    "    # Paper on WADA SNR:\n",
    "    #   http://www.cs.cmu.edu/~robust/Papers/KimSternIS08.pdf\n",
    "    #\n",
    "    # This function was adapted from this matlab code:\n",
    "    #   https://labrosa.ee.columbia.edu/projects/snreval/#9\n",
    "\n",
    "    # init\n",
    "    eps = 1e-10\n",
    "    # next 2 lines define a fancy curve derived from a gamma distribution -- see paper\n",
    "    db_vals = np.arange(-20, 101)\n",
    "    g_vals = np.array([0.40974774, 0.40986926, 0.40998566, 0.40969089, 0.40986186, 0.40999006, 0.41027138, 0.41052627, 0.41101024, 0.41143264, 0.41231718, 0.41337272, 0.41526426, 0.4178192 , 0.42077252, 0.42452799, 0.42918886, 0.43510373, 0.44234195, 0.45161485, 0.46221153, 0.47491647, 0.48883809, 0.50509236, 0.52353709, 0.54372088, 0.56532427, 0.58847532, 0.61346212, 0.63954496, 0.66750818, 0.69583724, 0.72454762, 0.75414799, 0.78323148, 0.81240985, 0.84219775, 0.87166406, 0.90030504, 0.92880418, 0.95655449, 0.9835349 , 1.01047155, 1.0362095 , 1.06136425, 1.08579312, 1.1094819 , 1.13277995, 1.15472826, 1.17627308, 1.19703503, 1.21671694, 1.23535898, 1.25364313, 1.27103891, 1.28718029, 1.30302865, 1.31839527, 1.33294817, 1.34700935, 1.3605727 , 1.37345513, 1.38577122, 1.39733504, 1.40856397, 1.41959619, 1.42983624, 1.43958467, 1.44902176, 1.45804831, 1.46669568, 1.47486938, 1.48269965, 1.49034339, 1.49748214, 1.50435106, 1.51076426, 1.51698915, 1.5229097 , 1.528578  , 1.53389835, 1.5391211 , 1.5439065 , 1.54858517, 1.55310776, 1.55744391, 1.56164927, 1.56566348, 1.56938671, 1.57307767, 1.57654764, 1.57980083, 1.58304129, 1.58602496, 1.58880681, 1.59162477, 1.5941969 , 1.59693155, 1.599446  , 1.60185011, 1.60408668, 1.60627134, 1.60826199, 1.61004547, 1.61192472, 1.61369656, 1.61534074, 1.61688905, 1.61838916, 1.61985374, 1.62135878, 1.62268119, 1.62390423, 1.62513143, 1.62632463, 1.6274027 , 1.62842767, 1.62945532, 1.6303307 , 1.63128026, 1.63204102])\n",
    "\n",
    "    # peak normalize, get magnitude, clip lower bound\n",
    "    wav = np.array(wav)\n",
    "    wav = wav / abs(wav).max()\n",
    "    abs_wav = abs(wav)\n",
    "    abs_wav[abs_wav < eps] = eps\n",
    "\n",
    "    # calcuate statistics\n",
    "    # E[|z|]\n",
    "    v1 = max(eps, abs_wav.mean())\n",
    "    # E[log|z|]\n",
    "    v2 = np.log(abs_wav).mean()\n",
    "    # log(E[|z|]) - E[log(|z|)]\n",
    "    v3 = np.log(v1) - v2\n",
    "\n",
    "    # table interpolation\n",
    "    wav_snr_idx = None\n",
    "    if any(g_vals < v3):\n",
    "        wav_snr_idx = np.where(g_vals < v3)[0].max()\n",
    "    # handle edge cases or interpolate\n",
    "    if wav_snr_idx is None:\n",
    "        wav_snr = db_vals[0]\n",
    "    elif wav_snr_idx == len(db_vals) - 1:\n",
    "        wav_snr = db_vals[-1]\n",
    "    else:\n",
    "        wav_snr = db_vals[wav_snr_idx] + \\\n",
    "            (v3-g_vals[wav_snr_idx]) / (g_vals[wav_snr_idx+1] - \\\n",
    "            g_vals[wav_snr_idx]) * (db_vals[wav_snr_idx+1] - db_vals[wav_snr_idx])\n",
    "\n",
    "    # Calculate SNR\n",
    "    dEng = sum(wav**2)\n",
    "    dFactor = 10**(wav_snr / 10)\n",
    "    dNoiseEng = dEng / (1 + dFactor) # Noise energy\n",
    "    dSigEng = dEng * dFactor / (1 + dFactor) # Signal energy\n",
    "    snr = 10 * np.log10(dSigEng / dNoiseEng)\n",
    "\n",
    "    return snr\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228d065-3388-4aa3-b09a-cf4f19ccc57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d18c02f1-bbc0-4e2b-9eda-bbb2800a34a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/a/Desktop/MSP-Podcast/pipeline/'\n",
    "\n",
    "output_location = 'INPUTS_OUTPUTS/Outputs/'\n",
    "\n",
    "with open(os.path.join(os.path.join(root, output_location), \"Short_files.json\"), \"r\") as openfile:\n",
    "    audio_files = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a78511-b57c-4087-b642-ec0ee26ca312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:04<00:00, 113.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter Rule (music detection)\n",
    "for filename, f_info in tqdm(audio_files.items()):\n",
    "    f_path = f_info['filepaths']['wav']\n",
    "    music_info = f_info['speech_music_pred']\n",
    "    speech_time = []\n",
    "    music_time = []\n",
    "        \n",
    "    for j in range(len(music_info)):\n",
    "        if music_info[j][2]=='speech':\n",
    "            speech_time.append(float(music_info[j][1])-float(music_info[j][0]))\n",
    "        elif music_info[j][2]=='music':\n",
    "            music_time.append(float(music_info[j][1])-float(music_info[j][0]))\n",
    "    # decision rule: music portion > 50% of total => filter\n",
    "        \n",
    "    if (sum(speech_time)+sum(music_time)) == 0:\n",
    "        f_info['music_ratio'] = 0\n",
    "    elif sum(music_time)/(sum(speech_time)+sum(music_time)):\n",
    "        f_info['music_ratio'] = sum(music_time)/(sum(speech_time)+sum(music_time))\n",
    "    else: #sanity check (should not happen)\n",
    "        f_info['music_ratio'] = 0\n",
    "        \n",
    "    #calculate SNR\n",
    "    _, x = wavfile.read(f_path)\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    snr = wada_snr(x)\n",
    "    # SNR threshold: above 15-20dB\n",
    "    f_info['SNR'] = snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af63c35f-6261-41d6-b9e3-48ad3bf16dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(audio_files, indent=4)\n",
    "with open(os.path.join(root, output_location, \"Short_files.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e424e-3d7b-4fe3-80a9-38aeaa8adeac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a952555-9730-4651-8452-5c3d1892f7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cf5a6-8cf6-4a1b-bf98-115e096e5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdd83e-bbc4-49f8-ab37-0e1ccefcdb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.join(root, output_location), \"Short_files.json\"), \"r\") as openfile:\n",
    "    audio_files = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db6f21-a40a-4785-bd62-5a1936f36cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, val in audio_files.items():\n",
    "    val['ranknet_wav2vec_features'] = val['wav2vec_features'].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac552d75-f2d3-4d9d-830e-d9500a7c0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = audio_files['MSP-PODCAST_5198_0033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256ad91-5e18-4ddf-8515-c38db40eda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe083b1-d6ea-4851-b32b-373f41d6ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del val['opensmile_hld']\n",
    "del val['opensmile_lld']\n",
    "del val['ranknet_wav2vec_features']\n",
    "del val['facebook_wav2vec_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168e2cb-7a8b-4acc-a031-d15731fdac42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a84241-b06d-4b16-8f1c-a8917dd3d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/a/Desktop/MSP-Podcast/pipeline/'\n",
    "\n",
    "output_location = 'INPUTS_OUTPUTS/Outputs/'\n",
    "# with open(os.path.join(os.path.join(root, output_location), \"Short_files.json\"), \"r\") as openfile:\n",
    "#     audio_files = json.load(openfile)\n",
    "\n",
    "\n",
    "to_be_processed = os.path.join(root,output_location,  'Short_split_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218e884-f257-47fc-8136-4cfa7a762d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = os.listdir(to_be_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d18d60-c328-4173-9a7a-7beb1eea39c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d8e94-32ac-4c5b-9294-7139dc37446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(audio_files, indent=4)\n",
    "with open(os.path.join(root, output_location, \"Short_files.json\"), \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4231b4-0de7-4d2b-a06c-bcff65b4341c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winston_base",
   "language": "python",
   "name": "winston_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
